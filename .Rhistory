a <- available.packages()
head(rownames(a),3)  ## show the names of first few pkgs
install.packages("slidify")
install.packages(c("ggplot2","slidify"))
library(ggplot2)
library(ggplot2)
search()
q()
makeVector <- function(x = numeric())
{
m <- NULL
set <- function(y)
{
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
makeVector(5)
p<-makeVector(5)
p
?is.null
?!is.null
makeCacheMatrix <- function(x = matrix())
{
## x represents an invertible matrix
## This function creates a special "matrix" object that can cache its inverse
##              1. set the matrix
##              2. get the matrix
##              3. set the inverse
##              4. get the inverse
##         this list is used as the input to cacheSolve()
i = NULL
set = function(y)
{
# `<<-` is used to assign a value to an object
# in an environment different from the current environment.
x <<- y
i <<- NULL
}
get = function()
{x}
setinv = function(inverse) i <<- inverse
getinv = function()
{i}
list(set=set, get=get, setinv=setinv, getinv=getinv)
}
cacheSolve <- function(x, ...)
{
## Use the output of makeCacheMatrix()function
## This function returns inverse of the original matrix input to          makeCacheMatrix()
i = x$getinv()
## This is to check if the inverse is already estimated
if (!is.null(i))
{
## If yes, get it from the cache and skip the calculation.
message("Get the cached data")
return(i)
}
## If not, calculate the inverse
matrix.data = x$get()
## solve(x) returns the inverse of the matrix
i = solve(matrix.data, ...)
# Set the value of the inverse in the cache via the setinv function.
x$setinv(i)
return(i)
}
makeCacheMatrix(1:4,2,2)
makeCacheMatrix(1:4)
cacheSolve(1:4)
q()
install.packages('RMySQL',type='source')
https://class.coursera.org/getdata-032/forum/thread?thread_id=28
library(RMySQL)
install.packages("RMySQL")
library(RMySQL)
q()
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "56b637a5baffac62cad9",
3c2d4a715083ff0d875aq()
myapp <- oauth_app("github",
key= "3c2d4a715083ff0d875a",
secret = "ed0ac1e3e8b19cc1c780d1fd08aeb5b6c7483e80")
github_token<- oauth2.0_token(outh_endpoints("github"), myapp)
github_token<- oauth2.0_token(outh_endpoints("github"), myapp)
github_token<- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken<-config(token = github_token)
red <- GET("https://api.github.com/users/jtleek/repos",gtoken)
stop_for_status(red)
content(red)
req <- GET("https://api.github.com/users/jtleek/repos",gtoken)
stop_for_status(req)
https://api.github.com/users/jtleek/repos
content(req)
list(output[[4]]$name,output[[4]]$created_at)
output<- content(req)
list(output[[4]]$name,output[[4]]$created_at)
library(httr)
require(httpuv)
require(jsonlite)
oauth_endpoints("github")
myapp <- oauth_app("github","3c2d4a715083ff0d875a",secret="ed0ac1e3e8b19cc1c780d1fd08aeb5b6c7483e80")
github_token<- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/jtleek/repos",config(token=github_token))
stop_for_status(req)
output<- content(req)
list(output[[4]]$name,output[[4]]$created_at)
github_token<- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/jtleek/repos",config(token=github_token))
stop_for_status(req)
github_token<- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/jtleek/repos",config(token=github_token))
stop_for_status(req)
github_token<- oauth2.0_token(oauth_endpoints("github"), myapp,cache=FALSE)
req <- GET("https://api.github.com/users/jtleek/repos",config(token=github_token))
stop_for_status(req)
q()
df <- dbConnect(MySQL(),user="genome", db="getdata-data-ss06pid",host="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
install.packages("sqldf")
library(sqldf)
df <- dbConnect(MySQL(),user="genome", db="getdata-data-ss06pid",host="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
df <- dbConnect(MySQL(),user="swati", db="getdata-data-ss06pid",host="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
library(MySQL)
install.packages("MySQL")
?"dbConnect"
df <- dbConnect(RMySQL()),user="swati", db="getdata-data-ss06pid",host="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
df <- dbConnect(RMySQL(),user="swati", db="getdata-data-ss06pid",host="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
install.packages("RMySQL")
library(RMySQL)
df <- dbConnect(RMySQL(),user="swati", db="getdata-data-ss06pid",host="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
install.packages("RSQLite")
install.packages("RSQLite")
library(RSQLite)
df <- dbConnect(RSQLite(),host="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
con = url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readLines(con)
close(con)
htmlCode
htmlCode[10]
htmlCode[180]
q()
library(reshape2)
## STEP 1: Merge the training and the test datasets to create one single data set
# read the individual subject data, measurement & labels data into data frames for training data sets
subject_train <- read.table("subject_train.txt")
X_train <- read.table("X_train.txt")
Y_train <- read.table("y_train.txt")
# add column name for subject files
names(subject_train) <- "subject_ID"
# add column names for measurement files
featureNames <- read.table("features.txt")
names(X_train) <- featureNames$V2
# add column name for label files
names(Y_train) <- "activity"
# combine files of training details into one dataset
train <- cbind(subject_train, Y_train, X_train)
# read the individual subject data, measurement & labels data into data frames for test data sets
subject_test <- read.table("subject_test.txt")
X_test <- read.table("X_test.txt")
Y_test <- read.table("y_test.txt")
# add column name for subject files
names(subject_test) <- "subject_ID"
# add column names for measurement files
names(X_test) <- featureNames$V2
# add column name for label files
names(Y_test) <- "activity"
# combine Test data files into one dataset
test <- cbind(subject_test, Y_test, X_test)
# Combine the Training and Test Datasets
combined <- rbind(train, test)
## STEP 2: Extracts only the measurements on the mean and standard deviation for each measurement
# determine which columns contain "mean()" or "std()"
meanstdcols <- grepl("mean\\(\\)", names(combined)) |
grepl("std\\(\\)", names(combined))
# ensure that we also keep the subjectID and activity columns
meanstdcols[1:2] <- TRUE
# remove unnecessary columns
combined <- combined[, meanstdcols]
## STEP 3: Uses descriptive activity names to name the activities in the data set
## STEP 4: Appropriately label the data set with descriptive activity names
# convert the activity column from integer to factor
combined$activity <- factor(combined$activity, labels=c("Walking",
"Walking Upstairs", "Walking Downstairs", "Sitting", "Standing", "Laying"))
## STEP 5: Creates a second, independent tidy data set with the
## average of each variable for each activity and each subject.
# create the tidy data set
melted <- melt(combined, id=c("subjectID","activity"))
tidy <- dcast(melted, subjectID+activity ~ variable, mean)
# write the tidy data set to a file
write.csv(tidy, "tidy.csv", row.names=FALSE)
source('~/R_Progs/Assignment1-DataCleaning/run_Analysis.R')
q()
setwd("~/R_Progs/Assignment1-DataCleaning")
subject_train <- read.table("subject_train.txt")
X_train <- read.table("X_train.txt")
Y_train <- read.table("y_train.txt")
X_train <- read.table("./UCI HAR Dataset/train/X_train.txt")
Y_train <- read.table("./UCI HAR Dataset/train/y_train.txt")
# add column name for subject files
names(subject_train) <- "subject_ID"
# add column names for measurement files
featureNames <- read.table("features.txt")
names(X_train) <- featureNames$V2
names(./UCI HAR Dataset/train/subject_train) <- "subject_ID"
names("./UCI HAR Dataset/train/subject_train") <- "subject_ID"
q()
